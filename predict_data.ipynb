{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "##############################\n",
    "from models import deeplab_xception\n",
    "from models import tiramisu\n",
    "from models import unet\n",
    "from datasets import datasets\n",
    "from utils import manager as mgr\n",
    "from utils import img_utils\n",
    "##############################\n",
    "\n",
    "# set device\n",
    "#device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "exp_name = 'unet_df_030_001'\n",
    "#WEIGHTS_PATH = '/home/philipp/Data/weights/'+exp_name+'/'\n",
    "WEIGHTS_PATH = '/home/philipp/Code/python/edin_prediction/weights/'\n",
    "#device = \"cuda:0\"\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "architecture = 'deeplab'#'deeplab'#'densenet'\n",
    "nr_channels = 7\n",
    "nr_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 4\n",
      "Output stride: 16\n",
      "Number of Input Channels: 7\n",
      "loading weights '/home/philipp/Code/python/edin_prediction/weights/deeplab_weights-21-0.192-0.818.pth'\n",
      "loaded weights (lastEpoch 20, loss 0.19151103496551514, error 0.8182618618011475)\n",
      "weights loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabv3_plus(\n",
       "  (xception_features): Xception(\n",
       "    (conv1): Conv2d(7, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (block1): Block(\n",
       "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block2): Block(\n",
       "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block3): Block(\n",
       "      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block4): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block6): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block7): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block8): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block9): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block10): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block11): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block12): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block13): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block14): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block15): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block16): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block17): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block18): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block19): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block20): Block(\n",
       "      (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): SeparableConv2d_same(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), groups=1024, bias=False)\n",
       "          (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): SeparableConv2d_same(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1024, bias=False)\n",
       "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): SeparableConv2d_same(\n",
       "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
       "      (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn4): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5): SeparableConv2d_same(\n",
       "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
       "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (aspp1): ASPP_module(\n",
       "    (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (aspp2): ASPP_module(\n",
       "    (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (aspp3): ASPP_module(\n",
       "    (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (aspp4): ASPP_module(\n",
       "    (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (global_avg_pool): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (last_conv): Sequential(\n",
       "    (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if architecture == 'unet':\n",
    "    model = unet.UNET(in_channels=nr_channels, out_channels=nr_classes)\n",
    "    weights_name = 'unet_weights-19-0.217-0.821.pth'\n",
    "    \n",
    "elif architecture == 'densenet':\n",
    "    model = tiramisu.FCDenseNet57(in_channels=nr_channels, n_classes=nr_classes)\n",
    "    weights_name = 'densenet_weights-3-0.186-0.808.pth'\n",
    "    \n",
    "elif architecture == 'deeplab':\n",
    "    model = deeplab_xception.DeepLabv3_plus(nInputChannels=nr_channels, n_classes=nr_classes, os=16, pretrained=False)\n",
    "    weights_name = 'deeplab_weights-21-0.192-0.818.pth'\n",
    "    \n",
    "else:\n",
    "    print('provide architecture')\n",
    "    \n",
    "try:\n",
    "    mgr.load_weights(model, WEIGHTS_PATH+weights_name)\n",
    "    print(\"weights loaded\")\n",
    "except:\n",
    "    model.apply(mgr.weights_init)\n",
    "    print(\"no weights found\")\n",
    "    \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    '''Characterizes a dataset for PyTorch'''\n",
    "\n",
    "    def __init__(self, path):\n",
    "        '''Initialization'''\n",
    "        # open dataset\n",
    "        self.dset = h5py.File(path, 'r')\n",
    "        self.ortho = self.dset['ortho']\n",
    "        self.dsm = self.dset['dsm']\n",
    "        self.dtm = self.dset['dtm']\n",
    "        self.slope = self.dset['slope']\n",
    "\n",
    "        # set number of samples\n",
    "        self.dataset_size = 10679\n",
    "\n",
    "        ## TODO:\n",
    "        # make means and stds load from hdf5\n",
    "        self.means_tams = np.array([56.12055784563426, 62.130400134006976, 53.03228547781888, 119.50916281232037], dtype='float32')\n",
    "        self.stds_tams = np.array([30.37628560708646, 30.152693706272483, 23.13718651792004, 49.301477498205074], dtype='float32')\n",
    "\n",
    "        self.means_dsm = np.array([13.45]).astype(np.float32)\n",
    "        self.stds_dsm = np.array([10.386633252098674]).astype(np.float32)\n",
    "\n",
    "        self.means_dtm = np.array([1446.0]).astype(np.float32)\n",
    "        self.stds_dtm = np.array([271.05322202384195]).astype(np.float32)\n",
    "\n",
    "        self.means_slope = np.array([22.39]).astype(np.float32)\n",
    "        self.stds_slope = np.array([11.69830556896441]).astype(np.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return self.dataset_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "\n",
    "        # depending on data change mean and std\n",
    "        means = self.means_tams\n",
    "        stds = self.stds_tams\n",
    "\n",
    "        # Load data and get label\n",
    "        X_ortho = (torch.tensor(self.ortho[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - \\\n",
    "            means[:, np.newaxis, np.newaxis]) / stds[:, np.newaxis, np.newaxis]\n",
    "        X_dsm = (torch.tensor(self.dsm[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_dsm) / self.stds_dsm\n",
    "        X_dtm = (torch.tensor(self.dtm[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_dtm) / self.stds_dtm\n",
    "        X_slope = (torch.tensor(self.slope[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_slope) / self.stds_slope\n",
    "\n",
    "        X = torch.cat((X_ortho, X_dsm, X_dtm, X_slope),0)\n",
    "\n",
    "        return X #torch.from_numpy(y).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        ''' closes the hdf5 file'''\n",
    "        self.dset.close()\n",
    "\n",
    "\n",
    "    def show_item(self, index):\n",
    "        '''shows the data'''\n",
    "        #plt.imshow(np.array(self.ground_truth[index]))\n",
    "\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "        dic_data = {'RGB' : [np.array(self.ortho[index][:,:,:3]), [0.1, 0.3, 0.5, 0.7]], \\\n",
    "        'CIR' : [np.array(np.roll(self.ortho[index], 1, axis=2)[:,:,:3]), [0.1, 0.3, 0.5, 0.7]], \\\n",
    "        'DSM' : [np.array(self.dsm[index].astype('f')), [10, 20, 30]], \\\n",
    "        'DTM' : [np.array(self.dtm[index].astype('f')), [10, 20, 30]], \\\n",
    "        'Slope' : [np.array(self.slope[index].astype('f')), [10, 20, 30]]}\n",
    "\n",
    "        for i, key in enumerate(dic_data):\n",
    "            ax = fig.add_subplot(2, 3, i+1)\n",
    "            imgplot = plt.imshow(dic_data[key][0])\n",
    "            ax.set_title(key)\n",
    "            plt.colorbar(ticks=dic_data[key][1], orientation='horizontal')\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the dataset\n",
    "#path_dataset = \"/home/philipp/Data/dataset_256_df_2.h5\"\n",
    "path_dataset = \"/media/philipp/DATA/dataset/dataset_512_df_prediction.h5\"\n",
    "#path_dataset = \"/media/philipp/DATA/dataset/dataset_256_df_2.h5\"\n",
    "\n",
    "# open dataset\n",
    "dataset = ForestDataset(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quatering(dataset, idx_start, idx_end):\n",
    "    ## prepare input data\n",
    "    # cut into 4 quaters = 1 x 7x512x512 -> 4 x 7x256x256\n",
    "    n = idx_end - idx_start\n",
    "    store = torch.zeros((n*4,7,256,256),dtype=torch.float32)\n",
    "\n",
    "    for j,i in enumerate(range(idx_start, idx_end)):\n",
    "        store[j*4] = dataset[i][:,:256,:256]\n",
    "        store[j*4+1] = dataset[i][:,256:,:256]\n",
    "        store[j*4+2] = dataset[i][:,:256,256:]\n",
    "        store[j*4+3] = dataset[i][:,256:,256:] \n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(store):\n",
    "    # get predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(store)\n",
    "    pred_256 = mgr.get_predictions(output).numpy()\n",
    "    return pred_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(pred_256, idx_start, idx_end):\n",
    "    ## prepare output data\n",
    "    # merge into 4 quaters = 4 x 256x256 -> 1 x 512x512\n",
    "    n = idx_end - idx_start\n",
    "    pred_512 = np.zeros((n,512,512), dtype=np.int8)\n",
    "    \n",
    "    for i in range(n):\n",
    "        j = i*4\n",
    "        pred_512[i,:256,:256] = pred_256[j]\n",
    "        pred_512[i,256:,:256] = pred_256[j+1]\n",
    "        pred_512[i,:256,256:] = pred_256[j+2]\n",
    "        pred_512[i,256:,256:] = pred_256[j+3]\n",
    "    return pred_512    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 512, 512)\n",
      "0 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 60\n",
      "60 90\n",
      "90 120\n",
      "120 150\n",
      "150 180\n",
      "180 210\n",
      "210 240\n",
      "240 270\n",
      "270 300\n",
      "300 330\n",
      "330 360\n",
      "360 390\n",
      "390 420\n",
      "420 450\n",
      "450 480\n",
      "480 510\n",
      "510 540\n",
      "540 570\n",
      "570 600\n",
      "600 630\n",
      "630 660\n",
      "660 690\n",
      "690 720\n",
      "720 750\n",
      "750 780\n",
      "780 810\n",
      "810 840\n",
      "840 870\n",
      "870 900\n",
      "900 930\n",
      "930 960\n",
      "960 990\n",
      "990 1020\n",
      "1020 1050\n",
      "1050 1080\n",
      "1080 1110\n",
      "1110 1140\n",
      "1140 1170\n",
      "1170 1200\n",
      "1200 1230\n",
      "1230 1260\n",
      "1260 1290\n",
      "1290 1320\n",
      "1320 1350\n",
      "1350 1380\n",
      "1380 1410\n",
      "1410 1440\n",
      "1440 1470\n",
      "1470 1500\n",
      "1500 1530\n",
      "1530 1560\n",
      "1560 1590\n",
      "1590 1620\n",
      "1620 1650\n",
      "1650 1680\n",
      "1680 1710\n",
      "1710 1740\n",
      "1740 1770\n",
      "1770 1800\n",
      "1800 1830\n",
      "1830 1860\n",
      "1860 1890\n",
      "1890 1920\n",
      "1920 1950\n",
      "1950 1980\n",
      "1980 2010\n",
      "2010 2040\n",
      "2040 2070\n",
      "2070 2100\n",
      "2100 2130\n",
      "2130 2160\n",
      "2160 2190\n",
      "2190 2220\n",
      "2220 2250\n",
      "2250 2280\n",
      "2280 2310\n",
      "2310 2340\n",
      "2340 2370\n",
      "2370 2400\n",
      "2400 2430\n",
      "2430 2460\n",
      "2460 2490\n",
      "2490 2520\n",
      "2520 2550\n",
      "2550 2580\n",
      "2580 2610\n",
      "2610 2640\n",
      "2640 2670\n",
      "2670 2700\n",
      "2700 2730\n",
      "2730 2760\n",
      "2760 2790\n",
      "2790 2820\n",
      "2820 2850\n",
      "2850 2880\n",
      "2880 2910\n",
      "2910 2940\n",
      "2940 2970\n",
      "2970 3000\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 3000\n",
    "batch = 30\n",
    "\n",
    "p = np.zeros((end-start,512,512), dtype=np.int8)\n",
    "print(p.shape)\n",
    "\n",
    "counter = start\n",
    "\n",
    "for i in range((end-start) // batch):\n",
    "    \n",
    "    store = print(counter, counter+batch)\n",
    "    \n",
    "    store = quatering(dataset=dataset, idx_start=counter, idx_end=counter+batch)\n",
    "    pred_256 = predict(store)\n",
    "    pred_512 = merge(pred_256, counter, counter+batch)\n",
    "    \n",
    "    p[i*batch:(i+1)*batch] = pred_512\n",
    "    \n",
    "    counter += batch\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 512, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_deeplab.npy', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7ebd2106b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "## prepare input data\n",
    "# cut into 4 quaters = 1 x 7x512x512 -> 4 x 7x256x256\n",
    "\n",
    "start = 0\n",
    "end = 40\n",
    "\n",
    "n = end - start\n",
    "store = torch.zeros((n*4,7,256,256),dtype=torch.float32)\n",
    "\n",
    "for i,j in enumerate(range(0,n*4,4)):\n",
    "    store[j] = dataset[i][:,:256,:256]\n",
    "    store[j+1] = dataset[i][:,256:,:256]\n",
    "    store[j+2] = dataset[i][:,:256,256:]\n",
    "    store[j+3] = dataset[i][:,256:,256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "with torch.no_grad():\n",
    "    output = model(store)\n",
    "p = mgr.get_predictions(output).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare output data\n",
    "# merge into 4 quaters = 4 x 7x256x256 -> 1 x 7x512x512\n",
    "\n",
    "pred = np.zeros((n,512,512), dtype=np.int8)\n",
    "\n",
    "for i,j in enumerate(range(0,n*4,4)):\n",
    "    pred[i,:256,:256] = p[j]\n",
    "    pred[i,256:,:256] = p[j+1]\n",
    "    pred[i,:256,256:] = p[j+2]\n",
    "    pred[i,256:,256:] = p[j+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 512, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 119.50916281232037\n",
    "std = 49.301477498205074\n",
    "\n",
    "i = 0\n",
    "l = 10000\n",
    "nirs = []\n",
    "\n",
    "for i in range(20):\n",
    "    # grab data\n",
    "    x = torch.stack([dataset[i][3], \\\n",
    "                    dataset[i+1*l][3], \\\n",
    "                    dataset[i+2*l][3], \\\n",
    "                    dataset[i+3*l][3]])\n",
    "    \n",
    "    # reconstruct tile\n",
    "    merged_512 = np.ones((512, 512))\n",
    "    # paste predicted data into array\n",
    "    merged_512[:256,:256] = dataset[i][3]\n",
    "    merged_512[256:,:256] = dataset[i+1*l][3]\n",
    "    merged_512[:256,256:] = dataset[i+2*l][3]\n",
    "    merged_512[256:,256:] = dataset[i+3*l][3]\n",
    "    \n",
    "    merged_512 = std * merged_512 + mean\n",
    "    \n",
    "    nirs.append(merged_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nirs = np.array(nirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nir.npy', nirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred.npy', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2raster(newRasterfn, dataset, array, dtype):\n",
    "    \"\"\"\n",
    "    save GTiff file from numpy.array\n",
    "    input:\n",
    "        newRasterfn: save file name\n",
    "        dataset : original tif file\n",
    "        array : numpy.array\n",
    "        dtype: Byte or Float32.\n",
    "    \"\"\"\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX, pixelWidth, b, originY, d, pixelHeight = dataset.GetGeoTransform() \n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    # set data type to save.\n",
    "    GDT_dtype = gdal.GDT_Unknown\n",
    "    if dtype == \"Byte\": \n",
    "        GDT_dtype = gdal.GDT_Byte\n",
    "    elif dtype == \"Float32\":\n",
    "        GDT_dtype = gdal.GDT_Float32\n",
    "    else:\n",
    "        print(\"Not supported data type.\")\n",
    "\n",
    "    # set number of band.\n",
    "    if array.ndim == 2:\n",
    "        band_num = 1\n",
    "    else:\n",
    "        band_num = array.shape[2]\n",
    "\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, band_num, GDT_dtype)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "\n",
    "    # Loop over all bands.\n",
    "    for b in range(band_num):\n",
    "        outband = outRaster.GetRasterBand(b + 1)\n",
    "        # Read in the band's data into the third dimension of our array\n",
    "        if band_num == 1:\n",
    "            outband.WriteArray(array)\n",
    "        else:\n",
    "            outband.WriteArray(array[:,:,b])\n",
    "\n",
    "    # setteing srs from input tif file.\n",
    "    prj=dataset.GetProjection()\n",
    "    outRasterSRS = osr.SpatialReference(wkt=prj)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.load('pred_deeplab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(dir_img, sort=False):\n",
    "    \"\"\"\n",
    "    find paths for provided data types\n",
    "    inputs:\n",
    "        dir_img (str) : directory path\n",
    "    return:\n",
    "        paths (dictionary) : dictionary containing file paths for each of the data types\n",
    "    \"\"\"\n",
    "\n",
    "    paths = []\n",
    "    # loop over all files found in directory and retrive indices\n",
    "    for file in os.listdir(\"{}\".format(dir_img)):\n",
    "        if file[-4:] == \".tif\":\n",
    "            paths.append(dir_img + file)\n",
    "\n",
    "    if sort:\n",
    "        paths = sorted(paths)\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = find_files('/media/philipp/DATA/2018_tamsweg/ortho/', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_121889.tif',\n",
       " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_121890.tif',\n",
       " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122277.tif']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_input[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10679"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to geotiff files\n",
    "for i, path_in in enumerate(path_input[:pred.shape[0]]):\n",
    "    path_out = 'foto/pred_{}.tif'.format(i)\n",
    "    dataset = gdal.Open(path_in, gdal.GA_ReadOnly)\n",
    "    array2raster(newRasterfn=path_out, dataset=dataset, array=pred[i], dtype='Byte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mosaik geotiff files\n",
    "\n",
    "def mosaik_raster(input_files, output_file):\n",
    "    \n",
    "    # set path to text file with all tif file paths to be merged\n",
    "    merge_list_path =  '/home/philipp/Code/python/edin_prediction/dtm_merge_list.txt'\n",
    "    # create txt file with all tif files needed\n",
    "    with open(merge_list_path, 'w+') as f:\n",
    "        for name in input_files:\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # create string containing bash command\n",
    "    cmd = \"gdal_merge.py -ot Byte -of GTiff -o {} --optfile {}\".format(output_file, merge_list_path)\n",
    "\n",
    "    # execute bash command\n",
    "    os.system(cmd)\n",
    "\n",
    "    print(\"DTM file created - files merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = find_files('/home/philipp/Code/python/edin_prediction/foto/', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM file created - files merged\n"
     ]
    }
   ],
   "source": [
    "output_file = '/home/philipp/Code/python/edin_prediction/pred/pred.tif'\n",
    "mosaik_raster(input_files, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_file = '/home/philipp/Code/python/edin_prediction/pred/pred.shp'\n",
    "# create vector (polygons) out of raster\n",
    "cmd = 'gdal_polygonize.py -8 {} -b 1 -f \"ESRI Shapefile\" {} output DF'.format(output_file, vector_file)\n",
    "# execute bash command\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2803.2375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42/160*10679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
