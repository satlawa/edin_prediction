{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "##############################\n",
    "from models import unet\n",
    "from datasets import datasets\n",
    "from utils import manager as mgr\n",
    "from utils import img_utils\n",
    "##############################\n",
    "\n",
    "# set device\n",
    "#device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "exp_name = 'unet_df_030_001'\n",
    "WEIGHTS_PATH = '/home/philipp/Data/weights/'+exp_name+'/'\n",
    "#device = \"cuda:0\"\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "nr_channels = 7\n",
    "nr_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights '/home/philipp/Data/weights/unet_df_030_001/weights-19-0.217-0.821.pth'\n",
      "loaded weights (lastEpoch 18, loss 0.21727018058300018, error 0.8208388090133667)\n",
      "weights loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (upconv4): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (upconv3): Sequential(\n",
       "    (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (upconv2): Sequential(\n",
       "    (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (upconv1): Sequential(\n",
       "    (0): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = unet.UNET(in_channels=nr_channels, out_channels=nr_classes)\n",
    "\n",
    "try:\n",
    "    mgr.load_weights(model, WEIGHTS_PATH+'weights-19-0.217-0.821.pth')\n",
    "    #load_weights(model, WEIGHTS_PATH+'latest_5d.pt')\n",
    "    print(\"weights loaded\")\n",
    "except:\n",
    "    model.apply(mgr.weights_init)\n",
    "    print(\"no weights found\")\n",
    "    \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    '''Characterizes a dataset for PyTorch'''\n",
    "\n",
    "    def __init__(self, path):\n",
    "        '''Initialization'''\n",
    "        # open dataset\n",
    "        self.dset = h5py.File(path, 'r')\n",
    "        self.ortho = self.dset['ortho']\n",
    "        self.dsm = self.dset['dsm']\n",
    "        self.dtm = self.dset['dtm']\n",
    "        self.slope = self.dset['slope']\n",
    "\n",
    "        # set number of samples\n",
    "        self.dataset_size = 10679\n",
    "\n",
    "        ## TODO:\n",
    "        # make means and stds load from hdf5\n",
    "        self.means_tams = np.array([56.12055784563426, 62.130400134006976, 53.03228547781888, 119.50916281232037], dtype='float32')\n",
    "        self.stds_tams = np.array([30.37628560708646, 30.152693706272483, 23.13718651792004, 49.301477498205074], dtype='float32')\n",
    "\n",
    "        self.means_dsm = np.array([13.45]).astype(np.float32)\n",
    "        self.stds_dsm = np.array([10.386633252098674]).astype(np.float32)\n",
    "\n",
    "        self.means_dtm = np.array([1446.0]).astype(np.float32)\n",
    "        self.stds_dtm = np.array([271.05322202384195]).astype(np.float32)\n",
    "\n",
    "        self.means_slope = np.array([22.39]).astype(np.float32)\n",
    "        self.stds_slope = np.array([11.69830556896441]).astype(np.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return self.dataset_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "\n",
    "        # depending on data change mean and std\n",
    "        means = self.means_tams\n",
    "        stds = self.stds_tams\n",
    "\n",
    "        # Load data and get label\n",
    "        X_ortho = (torch.tensor(self.ortho[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - \\\n",
    "            means[:, np.newaxis, np.newaxis]) / stds[:, np.newaxis, np.newaxis]\n",
    "        X_dsm = (torch.tensor(self.dsm[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_dsm) / self.stds_dsm\n",
    "        X_dtm = (torch.tensor(self.dtm[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_dtm) / self.stds_dtm\n",
    "        X_slope = (torch.tensor(self.slope[index], \\\n",
    "            dtype=torch.float32).permute(2, 0, 1) - self.means_slope) / self.stds_slope\n",
    "\n",
    "        X = torch.cat((X_ortho, X_dsm, X_dtm, X_slope),0)\n",
    "\n",
    "        return X #torch.from_numpy(y).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        ''' closes the hdf5 file'''\n",
    "        self.dset.close()\n",
    "\n",
    "\n",
    "    def show_item(self, index):\n",
    "        '''shows the data'''\n",
    "        #plt.imshow(np.array(self.ground_truth[index]))\n",
    "\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "        dic_data = {'RGB' : [np.array(self.ortho[index][:,:,:3]), [0.1, 0.3, 0.5, 0.7]], \\\n",
    "        'CIR' : [np.array(np.roll(self.ortho[index], 1, axis=2)[:,:,:3]), [0.1, 0.3, 0.5, 0.7]], \\\n",
    "        'DSM' : [np.array(self.dsm[index].astype('f')), [10, 20, 30]], \\\n",
    "        'DTM' : [np.array(self.dtm[index].astype('f')), [10, 20, 30]], \\\n",
    "        'Slope' : [np.array(self.slope[index].astype('f')), [10, 20, 30]]}\n",
    "\n",
    "        for i, key in enumerate(dic_data):\n",
    "            ax = fig.add_subplot(2, 3, i+1)\n",
    "            imgplot = plt.imshow(dic_data[key][0])\n",
    "            ax.set_title(key)\n",
    "            plt.colorbar(ticks=dic_data[key][1], orientation='horizontal')\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the dataset\n",
    "#path_dataset = \"/home/philipp/Data/dataset_256_df_2.h5\"\n",
    "path_dataset = \"/media/philipp/DATA/dataset/dataset_512_df_prediction.h5\"\n",
    "#path_dataset = \"/media/philipp/DATA/dataset/dataset_256_df_2.h5\"\n",
    "\n",
    "# open dataset\n",
    "dataset = ForestDataset(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "3 12\n",
      "3 13\n",
      "3 14\n",
      "3 15\n",
      "4 16\n",
      "4 17\n",
      "4 18\n",
      "4 19\n",
      "5 20\n",
      "5 21\n",
      "5 22\n",
      "5 23\n",
      "6 24\n",
      "6 25\n",
      "6 26\n",
      "6 27\n",
      "7 28\n",
      "7 29\n",
      "7 30\n",
      "7 31\n",
      "8 32\n",
      "8 33\n",
      "8 34\n",
      "8 35\n",
      "9 36\n",
      "9 37\n",
      "9 38\n",
      "9 39\n",
      "10 40\n",
      "10 41\n",
      "10 42\n",
      "10 43\n",
      "11 44\n",
      "11 45\n",
      "11 46\n",
      "11 47\n",
      "12 48\n",
      "12 49\n",
      "12 50\n",
      "12 51\n",
      "13 52\n",
      "13 53\n",
      "13 54\n",
      "13 55\n",
      "14 56\n",
      "14 57\n",
      "14 58\n",
      "14 59\n",
      "15 60\n",
      "15 61\n",
      "15 62\n",
      "15 63\n",
      "16 64\n",
      "16 65\n",
      "16 66\n",
      "16 67\n",
      "17 68\n",
      "17 69\n",
      "17 70\n",
      "17 71\n",
      "18 72\n",
      "18 73\n",
      "18 74\n",
      "18 75\n",
      "19 76\n",
      "19 77\n",
      "19 78\n",
      "19 79\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(range(0,20*4,4)):\n",
    "    print(i,j)\n",
    "    print(i,j+1)\n",
    "    print(i,j+2)\n",
    "    print(i,j+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare input data\n",
    "# cut into 4 quaters = 1 x 7x512x512 -> 4 x 7x256x256\n",
    "\n",
    "start = 0\n",
    "end = 40\n",
    "\n",
    "n = end - start\n",
    "store = torch.zeros((n*4,7,256,256),dtype=torch.float32)\n",
    "\n",
    "for i,j in enumerate(range(0,n*4,4)):\n",
    "    store[j] = dataset[i][:,:256,:256]\n",
    "    store[j+1] = dataset[i][:,256:,:256]\n",
    "    store[j+2] = dataset[i][:,:256,256:]\n",
    "    store[j+3] = dataset[i][:,256:,256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "with torch.no_grad():\n",
    "    output = model(store)\n",
    "p = mgr.get_predictions(output).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare output data\n",
    "# merge into 4 quaters = 4 x 7x256x256 -> 1 x 7x512x512\n",
    "\n",
    "pred = np.zeros((n,512,512), dtype=np.int8)\n",
    "\n",
    "for i,j in enumerate(range(0,n*4,4)):\n",
    "    pred[i,:256,:256] = p[j]\n",
    "    pred[i,256:,:256] = p[j+1]\n",
    "    pred[i,:256,256:] = p[j+2]\n",
    "    pred[i,256:,256:] = p[j+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 512, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 119.50916281232037\n",
    "std = 49.301477498205074\n",
    "\n",
    "i = 0\n",
    "l = 10000\n",
    "nirs = []\n",
    "\n",
    "for i in range(20):\n",
    "    # grab data\n",
    "    x = torch.stack([dataset[i][3], \\\n",
    "                    dataset[i+1*l][3], \\\n",
    "                    dataset[i+2*l][3], \\\n",
    "                    dataset[i+3*l][3]])\n",
    "    \n",
    "    # reconstruct tile\n",
    "    merged_512 = np.ones((512, 512))\n",
    "    # paste predicted data into array\n",
    "    merged_512[:256,:256] = dataset[i][3]\n",
    "    merged_512[256:,:256] = dataset[i+1*l][3]\n",
    "    merged_512[:256,256:] = dataset[i+2*l][3]\n",
    "    merged_512[256:,256:] = dataset[i+3*l][3]\n",
    "    \n",
    "    merged_512 = std * merged_512 + mean\n",
    "    \n",
    "    nirs.append(merged_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nirs = np.array(nirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nir.npy', nirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2raster(newRasterfn, dataset, array, dtype):\n",
    "    \"\"\"\n",
    "    save GTiff file from numpy.array\n",
    "    input:\n",
    "        newRasterfn: save file name\n",
    "        dataset : original tif file\n",
    "        array : numpy.array\n",
    "        dtype: Byte or Float32.\n",
    "    \"\"\"\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX, pixelWidth, b, originY, d, pixelHeight = dataset.GetGeoTransform() \n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    # set data type to save.\n",
    "    GDT_dtype = gdal.GDT_Unknown\n",
    "    if dtype == \"Byte\": \n",
    "        GDT_dtype = gdal.GDT_Byte\n",
    "    elif dtype == \"Float32\":\n",
    "        GDT_dtype = gdal.GDT_Float32\n",
    "    else:\n",
    "        print(\"Not supported data type.\")\n",
    "\n",
    "    # set number of band.\n",
    "    if array.ndim == 2:\n",
    "        band_num = 1\n",
    "    else:\n",
    "        band_num = array.shape[2]\n",
    "\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, band_num, GDT_dtype)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "\n",
    "    # Loop over all bands.\n",
    "    for b in range(band_num):\n",
    "        outband = outRaster.GetRasterBand(b + 1)\n",
    "        # Read in the band's data into the third dimension of our array\n",
    "        if band_num == 1:\n",
    "            outband.WriteArray(array)\n",
    "        else:\n",
    "            outband.WriteArray(array[:,:,b])\n",
    "\n",
    "    # setteing srs from input tif file.\n",
    "    prj=dataset.GetProjection()\n",
    "    outRasterSRS = osr.SpatialReference(wkt=prj)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.load('pred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = ['/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_121889.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_121890.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122277.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122278.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122279.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122280.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122647.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122648.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122649.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122650.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122651.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122652.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_122653.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123009.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123010.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123011.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123012.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123013.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123014.tif',\n",
    " '/media/philipp/DATA/2018_tamsweg/ortho/tile_ortho_123015.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, path_in in enumerate(path_input):\n",
    "    path_out = 'foto/pred_{}.tif'.format(i)\n",
    "    dataset = gdal.Open(path_in, gdal.GA_ReadOnly)\n",
    "    array2raster(newRasterfn=path_out, dataset=dataset, array=pred[i], dtype='Byte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
